import pdfplumber
import os
import streamlit as st
from dotenv import load_dotenv
import logging
# ë¬¸ì„œ ë¡œë”© ë° ì²˜ë¦¬
from langchain_community.document_loaders import DirectoryLoader, PDFPlumberLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
# OpenAI ë° ë²¡í„° ì €ì¥ì†Œ
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS

# LangChain í•µì‹¬ ì²´ì¸ ê´€ë ¨
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.runnables.history import RunnableWithMessageHistory

# í”„ë¡¬í”„íŠ¸ êµ¬ì„±
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

# Streamlitìš© ëŒ€í™” ê¸°ë¡
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory

# ë©€í‹° ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„
from langchain.retrievers.multi_query import MultiQueryRetriever

load_dotenv()

# ğŸ“„ PDF ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°

def load_pdf_with_tables(directory_path):
    docs = []
    for filename in os.listdir(directory_path):
        if filename.endswith(".pdf"):
            with pdfplumber.open(os.path.join(directory_path, filename)) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    text = page.extract_text() or ""
                    tables = page.extract_tables()

                    table_texts = []
                    for table in tables:
                        rows = ["\t".join(cell if cell is not None else "" for cell in row) for row in table if row]
                        table_texts.append("\n".join(rows))

                    full_text = text + "\n\n" + "\n\n".join(table_texts)
                    docs.append(Document(page_content=full_text, metadata={"source": filename, "page": page_num + 1}))
    return docs


@st.cache_resource
def load_pdf():
    file_path = "./dat" 
    return load_pdf_with_tables(file_path)



# ğŸ§  ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ë˜ëŠ” ë¡œë“œ
@st.cache_resource
def get_or_create_vectorstore():
    persist_directory = "./faissDb"
    embedding = OpenAIEmbeddings(model='text-embedding-3-small')

    if os.path.exists(os.path.join(persist_directory, "index.faiss")):
        return FAISS.load_local(persist_directory, embedding, allow_dangerous_deserialization=True)

    docs = load_pdf()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)
    split_docs = text_splitter.split_documents(docs)
    vectorstore = FAISS.from_documents(split_docs, embedding)
    vectorstore.save_local(persist_directory)
    return vectorstore

# ğŸ“‘ ë¬¸ì„œ í¬ë§·í„°
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


# ğŸ”— ì²´ì¸ êµ¬ì„±
@st.cache_resource
def chaining():
    vectorstore = get_or_create_vectorstore()
    
    # âœ… MultiQueryRetrieverë¡œ êµì²´
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
    from langchain.retrievers.multi_query import MultiQueryRetriever
    retriever = MultiQueryRetriever.from_llm(
        retriever=vectorstore.as_retriever(),
        llm=llm
    )

    # âœ… ë¡œê·¸ ì¶œë ¥ (ì›í•œë‹¤ë©´ ìœ ì§€)
    import logging
    logging.basicConfig()
    logging.getLogger("langchain.retrievers.multi_query").setLevel(logging.INFO)

    # ğŸ” íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì§ˆë¬¸ ë¦¬í¬ë§·
    contextualize_q_system_prompt = """Given a chat history and the latest user question \
    which might reference context in the chat history, formulate a standalone question \
    which can be understood without the chat history. Do NOT answer the question, \
    just reformulate it if needed and otherwise return it as is."""
    contextualize_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", contextualize_q_system_prompt),
            MessagesPlaceholder("history"),
            ("human", "{input}"),
        ]
    )

    # ğŸ§  ë‹µë³€ í”„ë¡¬í”„íŠ¸
    qa_system_prompt = """
    You are ëŒë¸Œ, a friendly and knowledgeable assistant who helps new university students.  
Always answer in Korean, using warm, polite, and easy-to-understand language. ğŸ˜Š  
Include appropriate emojis to make your responses feel approachable and friendly. ğŸŒŸ

Use the provided documents as your primary reference.  
When answering, include **all relevant information from the documents** without omitting any helpful detail.

If you also know accurate and relevant information beyond the documents, you may include it to help the user.  
You do not need to mention whether it came from the document or not.

If the information is not known to you, respond politely with:  
â€œì£„ì†¡í•´ìš”, ê·¸ ë¶€ë¶„ì€ ë¬¸ì„œì— ë‚˜ì™€ ìˆì§€ ì•Šì•„ìš”.â€  

If the user asks for a specific form or template:
1. Explain the purpose and usage of the form based on its name or contents.
2. If available, offer the file with a friendly download message.
3. If not available, let the user know kindly.

If the question is ambiguous, ask the user for clarification.  
Your goal is to be kind, clear, and as informative as possible using both documents and your own knowledge. ğŸ“š

    {context}
    """

    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", qa_system_prompt),
            MessagesPlaceholder("history"),
            ("human", "{input}"),
        ]
    )

    # ğŸ” ì²´ì¸ êµ¬ì„±
    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
    return rag_chain

TEMPLATE_MAP = {
    "ë‹¨ì²´": ["ë‹¨ì²´ë“±ë¡ì‹ ì²­ì„œ.docx"],
    "ë…¼ë¬¸": ["ë…¼ë¬¸ ì‘ì„± ê³„íšì„œ.docx"],
    "ë´‰ì‚¬": ["êµìœ¡ë´‰ì‚¬í™œë™ìŠ¹ì¸ì‹ ì²­ì„œ.docx", "êµìœ¡ë´‰ì‚¬í™œë™í™•ì¸ì„œ.docx", 'êµìœ¡ë´‰ì‚¬í™œë™ ì¼ì§€.hwp'],
    "ì‹¤ìŠµ": ["ì‹¤ìŠµì‹ ì²­ì„œ.docx", "ì‹¤ìŠµë³´ê³ ì„œ ì‘ì„± ê³„íšì„œ.docx",
           'í•™êµí˜„ì¥ì‹¤ìŠµì§€ë„ ì•ˆë‚´ ë° ì¶œê·¼ë¶€, ê²°ê³¼ë³´ê³ ì„œ(ì–‘ì‹)_ìœ ì¹˜ì›.hwp',
           'í•™êµí˜„ì¥ì‹¤ìŠµì§€ë„ ì•ˆë‚´ ë° ì¶œê·¼ë¶€, ê²°ê³¼ë³´ê³ ì„œ(ì–‘ì‹)_ì¤‘ë“±í•™êµ.hwp',
           'í•™êµí˜„ì¥ì‹¤ìŠµì§€ë„ ì•ˆë‚´ ë° ì¶œê·¼ë¶€, ê²°ê³¼ë³´ê³ ì„œ(ì–‘ì‹)_íŠ¹ìˆ˜í•™êµ.hwp',
           'ê°œì¸ì •ë³´ ìˆ˜ì§‘.ì´ìš©. ì œ3ì ì œê³µ ë™ì˜ì„œ.hwp',
           '2025_í•™êµí˜„ì¥ì‹¤ìŠµì¼ì§€(ìœ ì¹˜ì›).hwp',
           '2025_í•™êµí˜„ì¥ì‹¤ìŠµì¼ì§€(ì¤‘ë“±í•™êµ).hwp',
           '2025_í•™êµí˜„ì¥ì‹¤ìŠµì¼ì§€(íŠ¹ìˆ˜í•˜êµ).hwp',
           "í•™êµí˜„ì¥ì‹¤ìŠµê²°ê³¼ë³´ê³ ì„œ.docx"],
    "ì¸ì‡„": ["ì¸ì‡„ë¬¼ë°°í¬ì›.docx"],
    "êµê³¼": ["êµì§ê³¼ëª© í•™ì ì¸ì •ì„œ.docx", "êµì§ê³¼ì •(ë³µìˆ˜ì „ê³µ)ì´ìˆ˜ì‹ ì²­ì„œ.docx"],
    "í‰ìƒêµìœ¡": [
        "í‰ìƒêµìœ¡ì‚¬ ìê²©ì¦ ë°œê¸‰ ì‹ ì²­ì„œ.hwp",
        "í‰ìƒêµìœ¡ì‚¬ ìê²©ì¦ ì¬ë°œê¸‰ì‹ ì²­ì„œ.docx",
        "í‰ìƒêµìœ¡ í˜„ì¥ì‹¤ìŠµ í‰ê°€ì„œ.docx",
        '(ì˜ˆì‹œ)í‰ìƒêµìœ¡ì‚¬ ìê²©ì¦ ë°œê¸‰ ì‹ ì²­ì„œ.pdf'
    ],
    "ì¡¸ì—…": ["ì¡°ê¸°ì¡¸ì—…ì‹ ì²­ì„œ.docx", "ì¡¸ì—…ìœ ë³´ì‹ ì²­ì„œ.docx", "ì¡¸ì—…ë…¼ë¬¸ê³„íšì„œ.docx"],
    "í™œë™": ["í™œë™ê³„íš ë° ì˜ˆì‚°ì„œ.docx"],
    "í•™ìƒ": ["í•™ìƒêµë¥˜ì§€ì›ì„œ.docx"],
    "í•™ì ": ["í•™ì êµë¥˜ì§€ì›ì„œ.docx"],
    "ìê²©ì¦": ["í•™ì êµë¥˜ì§€ì›ì„œ.docx",
            'ì˜ë¬¸êµì›ìê²©ì¦ë°œê¸‰ì‹ ì²­ì„œ.hwp',
            'ì‚¬ì„œìê²©ì¦ë°œê¸‰ì‹ ì²­ì„œ ì–‘ì‹.hwp',
            'êµì›ìê²©ì¦ ì¬êµë¶€ ì‹ ì²­ì„œ(ì–‘ì‹).hwp'],
    'êµì§': ['2025í•™ë…„ë„ ì…í•™ì êµì§ì´ìˆ˜ ê°€ì´ë“œ.hwp']
}
def match_template_keywords(message):
    if not message:
        return []
    
    trigger_words = ["ì–‘ì‹", "ì‹ ì²­ì„œ", "ì„œì‹", "ë‹¤ìš´ë¡œë“œ", "í¼", "ì„œë¥˜", "ì–‘ì‹ë“¤", "ì–‘ì‹ì¢€", "ì–‘ì‹ìš”", "í¼ì¢€"]
    return [
        k for k in TEMPLATE_MAP
        if k in message and any(trigger in message for trigger in trigger_words)
    ]



st.markdown(
    """
    <style>
        /* ì „ì²´ ë°°ê²½ */
        .stApp {
            background-color: #e3f3fc;
        }
    </style>
    """,
    unsafe_allow_html=True
)




# ğŸ–¼ï¸ ì•± ì¸í„°í˜ì´ìŠ¤ ì‹œì‘
st.header("ê°•ë‚¨ëŒ€ ì±—ë´‡ ğŸ‘")

rag_chain = chaining()
chat_history = StreamlitChatMessageHistory(key="chat_messages")

conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="history",
    output_messages_key="answer",
)

# 1. FAQ ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
st.markdown("""
    <h5 style="color:#333333; font-weight:bold;">ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ğŸ§</h5>
""", unsafe_allow_html=True)

faq_list = [
    "ê°•ë‚¨ëŒ€ ìˆœí™˜ë²„ìŠ¤ ì‹œê°„í‘œë¥¼ ì•Œë ¤ì¤˜",
    "ê°•ë‚¨ëŒ€ ì¡¸ì—… ì¡°ê±´ ì•Œë ¤ì¤˜",
    "êµí•™1íŒ€ ì „í™”ë²ˆí˜¸ ì•Œë ¤ì¤˜"
]

page_prefix = "gangnam"

for idx, faq in enumerate(faq_list):
    if st.button(f"{faq}", key=f"{page_prefix}_faq_{idx}", type="secondary"):
        st.session_state["faq_question"] = faq


if "docs_with_scores" not in st.session_state:
    st.session_state.docs_with_scores = []

if "download_list" not in st.session_state:
    st.session_state.download_list = []
    
# 2. ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
if "profile_message" not in st.session_state:
    st.session_state["profile_message"] = {
        "role": "assistant",
        "content": "ê°•ë‚¨ëŒ€ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´, ëŒë¸Œê°€ ì•Œë ¤ì¤„ê²Œìš”!ğŸ‘"
    }

if "messages" not in st.session_state:
    st.session_state["messages"] = []



# 3. ê¸°ì¡´ ëŒ€í™” ë Œë”ë§
profile = st.session_state["profile_message"]
with st.chat_message("assistant", avatar="./image/chat_ramb.jpg"):
    st.markdown(
        f"""
        <div style="background-color:#f0f8ff; padding: 10px; border-radius: 10px;">
            ğŸ“£ {profile["content"]}
        </div>
        """,
        unsafe_allow_html=True
    )


for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        with st.chat_message("assistant",avatar="./image/chat_ramb.jpg"):
            st.markdown(
                f"""
                <div style="background-color:#f0f8ff; padding: 15px; border-radius: 12px; font-size: 15px;">
                    {msg["content"]}
                </div>
                """,
                unsafe_allow_html=True
            )


        if "download_list" in msg:
            st.divider()
            for info in msg["download_list"]:
                filename = info["filename"]
                file_bytes = info["file_bytes"]
                mime_type = {
                    ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    ".pdf": "application/pdf",
                    ".hwp": "application/octet-stream"
                }.get(filename[filename.rfind("."):], "application/octet-stream")

                st.info(f"ğŸ“ íŒŒì¼ ë‹¤ìš´ë¡œë“œ: {filename}")
                st.download_button(
                    label=f"ğŸ“„ {filename} ë‹¤ìš´ë¡œë“œ",
                    data=file_bytes,
                    file_name=filename,
                    mime=mime_type,
                    key=filename
                )
    else:
        st.chat_message("user").write(msg["content"])

# 4. FAQ ì§ˆë¬¸ ì²˜ë¦¬ or ì¼ë°˜ ì…ë ¥ ì²˜ë¦¬
prompt_message = None
from_faq = False

if "faq_question" in st.session_state:
    prompt_message = st.session_state.pop("faq_question")
    from_faq = True  # <- FAQì—ì„œ ì™”ë‹¤ëŠ” í”Œë˜ê·¸ ì„¤ì •
    st.chat_message("user").write(prompt_message)

user_input = st.chat_input("ì œì¶œ ì–‘ì‹ê³¼ ê°•ë‚¨ëŒ€ ì •ë³´ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤!", key="gangnam_chat_input")

if user_input and not from_faq:
    prompt_message = user_input

if prompt_message:
    st.session_state.messages.append({"role": "user", "content": prompt_message})
    if not from_faq:
        st.chat_message("user").write(prompt_message)

    with st.spinner("ë‹µë³€ ì¤€ë¹„ ì¤‘..."):
        response = conversational_rag_chain.invoke(
            {"input": prompt_message},
            {"configurable": {"session_id": "any"}}
        )
        answer = response["answer"]

        vectorstore = get_or_create_vectorstore()
        docs_with_scores = vectorstore.similarity_search_with_score(prompt_message, k=3)

        download_list = []
        matched_keywords = match_template_keywords(prompt_message)
        for keyword in matched_keywords:
            filenames = TEMPLATE_MAP.get(keyword, [])
            for filename in filenames:
                file_path = os.path.join("./templates", filename)
                try:
                    with open(file_path, "rb") as f:
                        file_bytes = f.read()
                    answer += f"\n\nğŸ“ ì°¸ê³ ë¡œ, '{filename}' ì–‘ì‹ì€ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆì–´ìš”! ğŸ‘‡"
                    download_list.append({"filename": filename, "file_bytes": file_bytes})
                except FileNotFoundError:
                    answer += f"\n\nâš ï¸ '{filename}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ìš”. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”!"

        assistant_msg = {"role": "assistant", "content": answer}
        if download_list:
            assistant_msg["download_list"] = download_list

        # ë©”ì‹œì§€ì— ë‹¤ìš´ë¡œë“œ ë¦¬ìŠ¤íŠ¸ í¬í•¨í•´ ì €ì¥í•´ì•¼ UI ë Œë”ë§ ì‹œ ì½ì„ ìˆ˜ ìˆìŒ
        st.session_state.messages.append(assistant_msg)

        # ì„¸ì…˜ ìƒíƒœì— ì°¸ê³  ë¬¸ì„œ, ë‹¤ìš´ë¡œë“œ ë¦¬ìŠ¤íŠ¸ ì €ì¥
        st.session_state.docs_with_scores = docs_with_scores
        st.session_state.download_list = download_list

    # st.rerun() í˜¸ì¶œí•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ë Œë”ë§ìœ¼ë¡œ ë„˜ì–´ê°€ë„ë¡


# 2) UI ë Œë”ë§í•  ë•Œ
    with st.chat_message("assistant", avatar="./image/chat_ramb.jpg"):
        st.markdown(
            f"""
            <div style="background-color:#f0f8ff; padding: 15px; border-radius: 12px; font-size: 15px;">
                {answer}
            </div>
            """,
            unsafe_allow_html=True
        )
        with st.expander("ğŸ“‚ ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
            for doc, score in st.session_state.docs_with_scores:
                filename = os.path.basename(doc.metadata["source"])
                st.markdown(f"ğŸ“„ **{filename}** &nbsp;&nbsp;&nbsp; *(score: {score:.4f})*", help=doc.page_content)
        if st.session_state.download_list:
            st.divider()
            for info in st.session_state.download_list:
                st.info(f"ğŸ“ íŒŒì¼ ë‹¤ìš´ë¡œë“œ: {info['filename']}")
                st.download_button(
                    label=f"ğŸ“„ {info['filename']} ë‹¤ìš´ë¡œë“œ",
                    data=info["file_bytes"],
                    file_name=info["filename"],
                    mime=(
                        "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        if info["filename"].endswith(".docx")
                        else "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    ),
                    key=info["filename"])